"""
üê¶ Twitter Parser ‚Äî –ø–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ Nitter
–ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∫–∏—Ç–æ–≤ –∏ –Ω–æ–≤–æ—Å—Ç–∏ –ë–ï–ó API

–ò—Å—Ç–æ—á–Ω–∏–∫–∏:
- @whale_alert ‚Äî —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –∫–∏—Ç–æ–≤
- @WatcherGuru ‚Äî –±—ã—Å—Ç—Ä—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
- @lookonchain ‚Äî –¥–≤–∏–∂–µ–Ω–∏—è –∫–∏—Ç–æ–≤
- @EmberCN ‚Äî –∏–Ω—Å–∞–π–¥—ã
"""
import asyncio
import aiohttp
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from dataclasses import dataclass, field
from bs4 import BeautifulSoup

from app.core.logger import logger


@dataclass
class WhaleTransaction:
    """–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è –∫–∏—Ç–∞"""
    coin: str
    amount: float
    amount_usd: float
    from_wallet: str
    to_wallet: str
    tx_type: str  # "exchange_in", "exchange_out", "whale_move", "unknown"
    timestamp: datetime
    source: str
    raw_text: str
    
    @property
    def is_bearish(self) -> bool:
        """–ú–µ–¥–≤–µ–∂–∏–π —Å–∏–≥–Ω–∞–ª (–ø—Ä–∏—Ç–æ–∫ –Ω–∞ –±–∏—Ä–∂—É)"""
        return self.tx_type == "exchange_in" and self.amount_usd > 10_000_000
    
    @property
    def is_bullish(self) -> bool:
        """–ë—ã—á–∏–π —Å–∏–≥–Ω–∞–ª (–æ—Ç—Ç–æ–∫ —Å –±–∏—Ä–∂–∏)"""
        return self.tx_type == "exchange_out" and self.amount_usd > 10_000_000


@dataclass
class TwitterNews:
    """–ù–æ–≤–æ—Å—Ç—å –∏–∑ Twitter"""
    text: str
    author: str
    timestamp: datetime
    sentiment: str  # "bullish", "bearish", "neutral"
    importance: str  # "low", "medium", "high", "critical"
    coins_mentioned: List[str] = field(default_factory=list)


class TwitterParser:
    """
    üê¶ –ü–∞—Ä—Å–µ—Ä Twitter —á–µ—Ä–µ–∑ Nitter
    
    Nitter ‚Äî –±–µ—Å–ø–ª–∞—Ç–Ω–æ–µ –∑–µ—Ä–∫–∞–ª–æ Twitter –±–µ–∑ API
    
    ‚ö†Ô∏è –°–¢–ê–¢–£–°: –û–¢–ö–õ–Æ–ß–Å–ù ‚Äî Nitter –∏–Ω—Å—Ç–∞–Ω—Å—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã
    """
    
    def __init__(self):
        # ‚ö†Ô∏è –û–¢–ö–õ–Æ–ß–Å–ù ‚Äî Nitter –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
        self.enabled = False
        
        # –°–ø–∏—Å–æ–∫ Nitter –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤ (–±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç)
        self.nitter_instances = [
            "https://nitter.privacydev.net",
            "https://nitter.poast.org",
            "https://nitter.woodland.cafe",
            "https://nitter.esmailelbob.xyz",
            "https://nitter.tiekoetter.com",
            "https://nitter.net",
            "https://nitter.cz",
            "https://nitter.unixfox.eu",
        ]
        self.working_instance = None
        
        if not self.enabled:
            logger.warning("‚ö†Ô∏è Twitter Parser –û–¢–ö–õ–Æ–ß–Å–ù ‚Äî Nitter –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        
        # –ê–∫–∫–∞—É–Ω—Ç—ã –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
        self.whale_accounts = [
            "whale_alert",      # –û—Å–Ω–æ–≤–Ω–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
            "lookonchain",      # –î–≤–∏–∂–µ–Ω–∏—è –∫–∏—Ç–æ–≤
            "EmberCN",          # –ö–∏—Ç–∞–π—Å–∫–∏–µ –∏–Ω—Å–∞–π–¥—ã
        ]
        
        self.news_accounts = [
            "WatcherGuru",      # –ë—ã—Å—Ç—Ä—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
            "CryptoPotato_",    # –ê–≥—Ä–µ–≥–∞—Ç–æ—Ä
            "Cointelegraph",    # –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
            "BitcoinMagazine",  # BTC –Ω–æ–≤–æ—Å—Ç–∏
        ]
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ whale_alert
        self.amount_pattern = re.compile(r'([\d,]+(?:\.\d+)?)\s*(BTC|ETH|USDT|USDC|XRP|SOL|BNB|ADA|DOGE|AVAX|LINK)', re.I)
        self.usd_pattern = re.compile(r'\$([\d,]+(?:\.\d+)?)\s*(million|mil|M|billion|bil|B)?', re.I)
        
        # –ë–∏—Ä–∂–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
        self.exchanges = [
            "binance", "coinbase", "kraken", "bitfinex", "huobi", "okx", "okex",
            "bybit", "kucoin", "gate.io", "gemini", "bitstamp", "ftx", "crypto.com"
        ]
        
        # –ö—ç—à
        self.cache: Dict[str, List] = {}
        self.cache_time: Dict[str, datetime] = {}
        self.cache_duration = timedelta(minutes=2)
        
        logger.info("üê¶ Twitter Parser –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    async def _find_working_instance(self) -> Optional[str]:
        """–ù–∞–π—Ç–∏ —Ä–∞–±–æ—Ç–∞—é—â–∏–π Nitter –∏–Ω—Å—Ç–∞–Ω—Å"""
        
        # ‚ö†Ô∏è –ü–∞—Ä—Å–µ—Ä –æ—Ç–∫–ª—é—á—ë–Ω
        if not self.enabled:
            return None
        
        if self.working_instance:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ–Ω –µ—â—ë —Ä–∞–±–æ—Ç–∞–µ—Ç
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(
                        f"{self.working_instance}/whale_alert",
                        timeout=aiohttp.ClientTimeout(total=5)
                    ) as response:
                        if response.status == 200:
                            return self.working_instance
            except:
                self.working_instance = None
        
        async with aiohttp.ClientSession() as session:
            for instance in self.nitter_instances:
                try:
                    async with session.get(
                        f"{instance}/whale_alert",
                        timeout=aiohttp.ClientTimeout(total=5),
                        headers={"User-Agent": "Mozilla/5.0"}
                    ) as response:
                        if response.status == 200:
                            text = await response.text()
                            if 'timeline-item' in text or 'tweet-content' in text:
                                self.working_instance = instance
                                logger.info(f"üê¶ Nitter –∏–Ω—Å—Ç–∞–Ω—Å: {instance}")
                                return instance
                except Exception as e:
                    logger.debug(f"Nitter {instance} failed: {e}")
                    continue
        
        logger.warning("‚ö†Ô∏è –ù–µ—Ç —Ä–∞–±–æ—Ç–∞—é—â–∏—Ö Nitter –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤")
        return None
    
    async def _fetch_tweets(self, username: str, limit: int = 20) -> List[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–≤–∏—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cache_key = f"tweets_{username}"
        if cache_key in self.cache:
            if datetime.now() - self.cache_time.get(cache_key, datetime.min) < self.cache_duration:
                return self.cache[cache_key]
        
        instance = await self._find_working_instance()
        if not instance:
            return []
        
        tweets = []
        
        try:
            async with aiohttp.ClientSession() as session:
                url = f"{instance}/{username}"
                headers = {
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
                }
                
                async with session.get(url, headers=headers, timeout=aiohttp.ClientTimeout(total=15)) as response:
                    if response.status != 200:
                        logger.warning(f"üê¶ Nitter returned {response.status} for @{username}")
                        return []
                    
                    html = await response.text()
                    soup = BeautifulSoup(html, 'html.parser')
                    
                    # –ü–∞—Ä—Å–∏–º —Ç–≤–∏—Ç—ã
                    tweet_elements = soup.find_all('div', class_='timeline-item')[:limit]
                    
                    for element in tweet_elements:
                        try:
                            # –¢–µ–∫—Å—Ç —Ç–≤–∏—Ç–∞
                            content = element.find('div', class_='tweet-content')
                            if not content:
                                continue
                            text = content.get_text(strip=True)
                            
                            # –í—Ä–µ–º—è
                            time_elem = element.find('span', class_='tweet-date')
                            timestamp = datetime.now()  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
                            if time_elem:
                                time_link = time_elem.find('a')
                                if time_link and time_link.get('title'):
                                    try:
                                        timestamp = datetime.strptime(
                                            time_link['title'], 
                                            "%b %d, %Y ¬∑ %I:%M %p %Z"
                                        )
                                    except:
                                        pass
                            
                            tweets.append({
                                "text": text,
                                "author": username,
                                "timestamp": timestamp,
                            })
                            
                        except Exception as e:
                            continue
            
            # –ö—ç—à–∏—Ä—É–µ–º
            self.cache[cache_key] = tweets
            self.cache_time[cache_key] = datetime.now()
            
            logger.debug(f"üê¶ @{username}: {len(tweets)} —Ç–≤–∏—Ç–æ–≤")
            
        except Exception as e:
            logger.error(f"üê¶ Twitter fetch error for @{username}: {e}")
        
        return tweets
    
    def _parse_whale_transaction(self, tweet: Dict) -> Optional[WhaleTransaction]:
        """–†–∞—Å–ø–∞—Ä—Å–∏—Ç—å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –∫–∏—Ç–∞ –∏–∑ —Ç–≤–∏—Ç–∞"""
        
        text = tweet.get("text", "")
        
        # –ò—â–µ–º —Å—É–º–º—É –∏ –º–æ–Ω–µ—Ç—É
        amount_match = self.amount_pattern.search(text)
        if not amount_match:
            return None
        
        amount_str = amount_match.group(1).replace(",", "")
        coin = amount_match.group(2).upper()
        
        try:
            amount = float(amount_str)
        except:
            return None
        
        # –ò—â–µ–º —Å—É–º–º—É –≤ USD
        usd_match = self.usd_pattern.search(text)
        amount_usd = 0
        if usd_match:
            usd_str = usd_match.group(1).replace(",", "")
            multiplier = 1
            if usd_match.group(2):
                mult_text = usd_match.group(2).lower()
                if mult_text in ["million", "mil", "m"]:
                    multiplier = 1_000_000
                elif mult_text in ["billion", "bil", "b"]:
                    multiplier = 1_000_000_000
            try:
                amount_usd = float(usd_str) * multiplier
            except:
                pass
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
        text_lower = text.lower()
        tx_type = "unknown"
        from_wallet = "unknown"
        to_wallet = "unknown"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
        for exchange in self.exchanges:
            if f"from {exchange}" in text_lower or f"from #{exchange}" in text_lower:
                from_wallet = exchange
                tx_type = "exchange_out"  # –° –±–∏—Ä–∂–∏ = –±—ã—á–∏–π
            elif f"to {exchange}" in text_lower or f"to #{exchange}" in text_lower:
                to_wallet = exchange
                tx_type = "exchange_in"  # –ù–∞ –±–∏—Ä–∂—É = –º–µ–¥–≤–µ–∂–∏–π
        
        if "transferred" in text_lower and tx_type == "unknown":
            tx_type = "whale_move"
        
        return WhaleTransaction(
            coin=coin,
            amount=amount,
            amount_usd=amount_usd,
            from_wallet=from_wallet,
            to_wallet=to_wallet,
            tx_type=tx_type,
            timestamp=tweet.get("timestamp", datetime.now()),
            source=tweet.get("author", ""),
            raw_text=text
        )
    
    def _analyze_news_sentiment(self, text: str) -> tuple:
        """–ê–Ω–∞–ª–∏–∑ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞ –Ω–æ–≤–æ—Å—Ç–∏"""
        
        text_lower = text.lower()
        
        # –ë—ã—á—å–∏ —Å–ª–æ–≤–∞
        bullish_words = [
            "surge", "soar", "rally", "breakout", "bullish", "moon", "pump",
            "buy", "accumulate", "adoption", "partnership", "etf approved",
            "institutional", "all-time high", "ath", "green", "gains",
            "record", "milestone", "upgrade", "launch"
        ]
        
        # –ú–µ–¥–≤–µ–∂—å–∏ —Å–ª–æ–≤–∞
        bearish_words = [
            "crash", "dump", "plunge", "bearish", "sell", "liquidat",
            "hack", "scam", "ban", "regulation", "sec", "lawsuit",
            "bankrupt", "insolvent", "withdraw", "fear", "red",
            "losses", "down", "drop", "decline", "fall"
        ]
        
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Å–ª–æ–≤–∞
        critical_words = [
            "breaking", "urgent", "alert", "just in", "confirmed",
            "sec", "fed", "fomc", "trump", "biden", "ban", "etf",
            "halving", "approval", "reject"
        ]
        
        bullish_count = sum(1 for w in bullish_words if w in text_lower)
        bearish_count = sum(1 for w in bearish_words if w in text_lower)
        is_critical = any(w in text_lower for w in critical_words)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç
        if bullish_count > bearish_count + 1:
            sentiment = "bullish"
        elif bearish_count > bullish_count + 1:
            sentiment = "bearish"
        else:
            sentiment = "neutral"
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å
        if is_critical:
            importance = "critical"
        elif bullish_count + bearish_count > 3:
            importance = "high"
        elif bullish_count + bearish_count > 1:
            importance = "medium"
        else:
            importance = "low"
        
        return sentiment, importance
    
    def _extract_coins(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á—å —É–ø–æ–º—è–Ω—É—Ç—ã–µ –º–æ–Ω–µ—Ç—ã"""
        
        coins = []
        patterns = [
            r'\$([A-Z]{2,5})\b',  # $BTC, $ETH
            r'\b(BTC|ETH|SOL|BNB|XRP|ADA|DOGE|AVAX|LINK|DOT|MATIC)\b',
            r'#(Bitcoin|Ethereum|Solana|BNB|XRP|Cardano|Dogecoin)\b',
        ]
        
        text_upper = text.upper()
        
        for pattern in patterns:
            matches = re.findall(pattern, text_upper, re.I)
            coins.extend([m.upper() for m in matches])
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π
        name_map = {
            "BITCOIN": "BTC",
            "ETHEREUM": "ETH",
            "SOLANA": "SOL",
            "CARDANO": "ADA",
            "DOGECOIN": "DOGE",
        }
        
        normalized = []
        for coin in coins:
            normalized.append(name_map.get(coin, coin))
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        return list(set(normalized))
    
    async def get_whale_transactions(self, hours: int = 4) -> List[WhaleTransaction]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –∫–∏—Ç–æ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —á–∞—Å–æ–≤"""
        
        # ‚ö†Ô∏è –ü–∞—Ä—Å–µ—Ä –æ—Ç–∫–ª—é—á—ë–Ω
        if not self.enabled:
            return []
        
        transactions = []
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        for account in self.whale_accounts:
            tweets = await self._fetch_tweets(account, limit=30)
            
            for tweet in tweets:
                if tweet.get("timestamp", datetime.now()) < cutoff_time:
                    continue
                
                tx = self._parse_whale_transaction(tweet)
                if tx and tx.amount_usd > 1_000_000:  # –¢–æ–ª—å–∫–æ > $1M
                    transactions.append(tx)
            
            await asyncio.sleep(0.5)  # Rate limit
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        transactions.sort(key=lambda x: x.timestamp, reverse=True)
        
        logger.info(f"üêã –ù–∞–π–¥–µ–Ω–æ {len(transactions)} whale —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π")
        
        return transactions
    
    async def get_crypto_news(self, hours: int = 2) -> List[TwitterNews]:
        """–ü–æ–ª—É—á–∏—Ç—å –∫—Ä–∏–ø—Ç–æ –Ω–æ–≤–æ—Å—Ç–∏"""
        
        # ‚ö†Ô∏è –ü–∞—Ä—Å–µ—Ä –æ—Ç–∫–ª—é—á—ë–Ω
        if not self.enabled:
            logger.debug("Twitter Parser –æ—Ç–∫–ª—é—á—ë–Ω ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫")
            return []
        
        news = []
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        for account in self.news_accounts:
            tweets = await self._fetch_tweets(account, limit=20)
            
            for tweet in tweets:
                if tweet.get("timestamp", datetime.now()) < cutoff_time:
                    continue
                
                text = tweet.get("text", "")
                sentiment, importance = self._analyze_news_sentiment(text)
                coins = self._extract_coins(text)
                
                news_item = TwitterNews(
                    text=text[:500],
                    author=tweet.get("author", ""),
                    timestamp=tweet.get("timestamp", datetime.now()),
                    sentiment=sentiment,
                    importance=importance,
                    coins_mentioned=coins
                )
                news.append(news_item)
            
            await asyncio.sleep(0.5)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ –∏ –≤—Ä–µ–º–µ–Ω–∏
        importance_order = {"critical": 0, "high": 1, "medium": 2, "low": 3}
        news.sort(key=lambda x: (importance_order.get(x.importance, 4), -x.timestamp.timestamp()))
        
        logger.info(f"üì∞ –ù–∞–π–¥–µ–Ω–æ {len(news)} –Ω–æ–≤–æ—Å—Ç–µ–π")
        
        return news
    
    async def get_whale_summary(self) -> Dict:
        """–°–≤–æ–¥–∫–∞ –ø–æ –∫–∏—Ç–∞–º –¥–ª—è Whale AI"""
        
        # ‚ö†Ô∏è –ü–∞—Ä—Å–µ—Ä –æ—Ç–∫–ª—é—á—ë–Ω ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—É—é —Å–≤–æ–¥–∫—É
        if not self.enabled:
            return {
                "total_volume_usd": 0,
                "exchange_inflow": 0,
                "exchange_outflow": 0,
                "net_flow": 0,
                "sentiment": "neutral",
                "top_transactions": [],
                "by_coin": {},
                "status": "disabled"
            }
        
        transactions = await self.get_whale_transactions(hours=4)
        
        if not transactions:
            return {
                "total_volume_usd": 0,
                "exchange_inflow": 0,
                "exchange_outflow": 0,
                "net_flow": 0,
                "sentiment": "neutral",
                "top_transactions": [],
                "by_coin": {}
            }
        
        # –°—á–∏—Ç–∞–µ–º –ø–æ—Ç–æ–∫–∏
        inflow = sum(tx.amount_usd for tx in transactions if tx.tx_type == "exchange_in")
        outflow = sum(tx.amount_usd for tx in transactions if tx.tx_type == "exchange_out")
        total = sum(tx.amount_usd for tx in transactions)
        net_flow = outflow - inflow
        
        # –ü–æ –º–æ–Ω–µ—Ç–∞–º
        by_coin = {}
        for tx in transactions:
            if tx.coin not in by_coin:
                by_coin[tx.coin] = {"inflow": 0, "outflow": 0, "moves": 0}
            
            if tx.tx_type == "exchange_in":
                by_coin[tx.coin]["inflow"] += tx.amount_usd
            elif tx.tx_type == "exchange_out":
                by_coin[tx.coin]["outflow"] += tx.amount_usd
            else:
                by_coin[tx.coin]["moves"] += tx.amount_usd
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç
        if net_flow > 50_000_000:
            sentiment = "bullish"  # –û—Ç—Ç–æ–∫ —Å –±–∏—Ä–∂
        elif net_flow < -50_000_000:
            sentiment = "bearish"  # –ü—Ä–∏—Ç–æ–∫ –Ω–∞ –±–∏—Ä–∂–∏
        else:
            sentiment = "neutral"
        
        return {
            "total_volume_usd": total,
            "exchange_inflow": inflow,
            "exchange_outflow": outflow,
            "net_flow": net_flow,
            "sentiment": sentiment,
            "top_transactions": transactions[:5],
            "by_coin": by_coin,
            "tx_count": len(transactions)
        }
    
    def get_status_text(self) -> str:
        """–°—Ç–∞—Ç—É—Å –¥–ª—è Telegram"""
        
        instance_status = "‚úÖ " + self.working_instance.split("//")[1] if self.working_instance else "‚ùå –Ω–µ –Ω–∞–π–¥–µ–Ω"
        
        return f"""üê¶ *Twitter Parser*

*Nitter:* {instance_status}
*Whale –∞–∫–∫–∞—É–Ω—Ç—ã:* {', '.join(self.whale_accounts)}
*News –∞–∫–∫–∞—É–Ω—Ç—ã:* {', '.join(self.news_accounts)}
*–í –∫—ç—à–µ:* {len(self.cache)} –∑–∞–ø—Ä–æ—Å–æ–≤
"""


# Singleton
twitter_parser = TwitterParser()


async def get_whale_data() -> Dict:
    """–ü—É–±–ª–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∫–∏—Ç–æ–≤"""
    return await twitter_parser.get_whale_summary()


async def get_twitter_news() -> List[TwitterNews]:
    """–ü—É–±–ª–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π"""
    return await twitter_parser.get_crypto_news()
